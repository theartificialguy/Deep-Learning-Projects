{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZ_TKW4jmNi"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7hbPXE_mcj9"
      },
      "source": [
        "CREATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX9ppFdpjqBY",
        "outputId": "59b100e2-f93a-4416-bef8-44e54e141705"
      },
      "source": [
        "# To create an empty tensor:\n",
        "x = torch.empty(1) # give any dimensions eg = x; (x,y); (x,y,z); (p,q,r,s)\n",
        "print(x)\n",
        "\n",
        "x = torch.rand(2,2) # a random valued tensor\n",
        "print(x)\n",
        "\n",
        "x = torch.zeros(2,2) # zero valued tensor\n",
        "print(x)\n",
        "\n",
        "x = torch.ones(2,2, dtype=torch.int) # one valued tensor\n",
        "print(x)\n",
        "print(x.size()) # to print shape/size"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.4131e-38])\n",
            "tensor([[0.4630, 0.7778],\n",
            "        [0.4913, 0.5367]])\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1, 1],\n",
            "        [1, 1]], dtype=torch.int32)\n",
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqfuXj19jp8o",
        "outputId": "bd3fc3d8-c32a-4bfc-a048-6232920b33da"
      },
      "source": [
        "# Create torch tensor from python list\n",
        "x = torch.tensor([10.34, 4.75])\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10.3400,  4.7500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFXAzMjJmetj"
      },
      "source": [
        "BASIC OPERATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxSDLr-pjp6l",
        "outputId": "024c9558-c976-4fdb-f307-a247ae1cd261"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "z = x + y\n",
        "print(z)\n",
        "# or\n",
        "z = torch.add(x, y)\n",
        "print(z)\n",
        "# in-place operations, in pytorch in-place operations can be determined by \"_\"\n",
        "y.add_(x) # this will modify y tensor.\n",
        "print(y)\n",
        "\n",
        "# simimlarly, torch.sub, torch.div, torch.mul etc."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0965, 0.8588],\n",
            "        [0.9866, 1.7742]])\n",
            "tensor([[1.0965, 0.8588],\n",
            "        [0.9866, 1.7742]])\n",
            "tensor([[1.0965, 0.8588],\n",
            "        [0.9866, 1.7742]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSDISDwRngsU"
      },
      "source": [
        "SLICING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4rxjPAqjp4Z",
        "outputId": "36e38e72-fe1f-434e-b4c2-0d85e495b8a9"
      },
      "source": [
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0112, 0.2087, 0.7695],\n",
            "        [0.3967, 0.5818, 0.8789],\n",
            "        [0.7758, 0.9055, 0.0750],\n",
            "        [0.5277, 0.2321, 0.8348],\n",
            "        [0.3132, 0.9311, 0.5115]])\n",
            "tensor([0.0112, 0.3967, 0.7758, 0.5277, 0.3132])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFKIT4m2ngNR",
        "outputId": "fe32a4f7-c07f-49d0-a97e-dcc7ad82bd1b"
      },
      "source": [
        "# when you have only 1 element in your tensor, we can do this to get actual value:\n",
        "print(x[1, 1].item())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5817717909812927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBZTRfSJoTQ_"
      },
      "source": [
        "RESHAPING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HouHY6rvngEj",
        "outputId": "03b49fb4-4f6e-458e-aa45-003ddff1ac86"
      },
      "source": [
        "x = torch.rand(4, 4)\n",
        "print(x)\n",
        "\n",
        "y = x.view(16) # number of elements must be same !\n",
        "print(y)\n",
        "\n",
        "y = x.view(-1, 8) # -1 indicates okay pytorch calculate 1st dim yourself, i want 2nd dim to be 8"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5057, 0.3594, 0.5016, 0.0699],\n",
            "        [0.9506, 0.5339, 0.4988, 0.7699],\n",
            "        [0.9599, 0.8566, 0.8641, 0.9499],\n",
            "        [0.7621, 0.4866, 0.5395, 0.8142]])\n",
            "tensor([0.5057, 0.3594, 0.5016, 0.0699, 0.9506, 0.5339, 0.4988, 0.7699, 0.9599,\n",
            "        0.8566, 0.8641, 0.9499, 0.7621, 0.4866, 0.5395, 0.8142])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5oYryubo-xm"
      },
      "source": [
        "NUMPY TO TENSOR OR VICE-VERSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1HWrKGpngAK",
        "outputId": "fb9a3ac2-0045-4ee9-c6bc-d07b8fb63a70"
      },
      "source": [
        "# tensor to numpy array\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoqi7iGkpDcf",
        "outputId": "cbf1e42f-7fe3-4ffc-cd3b-2c1c264596b2"
      },
      "source": [
        "# numpy array to tensor\n",
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7qn-RkQpDYY"
      },
      "source": [
        "x = torch.ones(5, requires_grad=True)\n",
        "# required_grad is False by default,\n",
        "# if True, it means that it tells torch it will need to calc. the gradients for this tensor later in our optimization steps."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9N84qu4rUX6"
      },
      "source": [
        "AUTOGRAD - Gradient computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0_zP1VIpDVz",
        "outputId": "915cce30-603a-4d58-c84a-ebf4ddf94f64"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.6645, -0.1210, -0.2901], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwBOY_pxrocK",
        "outputId": "7196fe90-a0cf-4a39-edfc-f7e7c7f07a2b"
      },
      "source": [
        "y = x + 2\n",
        "print(y)\n",
        "# the \"grad_fn\" is created by torch as we mentioned \"requires_grad=True\", this basically creates gradients for backprop function.\n",
        "# so to perform backprop on y, we can use grad_fn on y.\n",
        "z = y*y*2\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# now if we apply backprop on z:\n",
        "z.backward() # dz/dx, we get these grads by \"jacobian vectors and thier partial derivatives, chain rule\"\n",
        "# if z wasn't a scalar, then we would have to provide the same dim tensor as like \"z\", eg:\n",
        "# v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
        "# z.backward(v)\n",
        "print(x.grad) # to get gradients values"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.6645, 1.8790, 1.7099], grad_fn=<AddBackward0>)\n",
            "tensor([14.1991,  7.0614,  5.8477], grad_fn=<MulBackward0>)\n",
            "tensor(9.0361, grad_fn=<MeanBackward0>)\n",
            "tensor([14.2106, 10.0214,  9.1196])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z287B74rt_J"
      },
      "source": [
        "# methods to prevent \"x\" from tracking the gradients:\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWPPJJRRrt7T",
        "outputId": "082c697a-05a8-490c-edc3-fd6ce33c79d6"
      },
      "source": [
        "# important things in training step:\n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(4):\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    print(weights.grad)\n",
        "    weights.grad.zero_() # to empty the gradients"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z97sdUMflHA7"
      },
      "source": [
        "BACKPROPAGATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQDXmS44rt5G",
        "outputId": "c13f7154-30a0-49ae-8e79-86470ab23ccd"
      },
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update the weights\n",
        "# next forward and backward pass"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZtMZrchm8Z5"
      },
      "source": [
        "AUTOGRAD AND GRADIENT DESCENT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn4CIBAilFoJ",
        "outputId": "f235358d-d6a9-4aba-fcb3-cc8c4e7af513"
      },
      "source": [
        "# First with numpy\n",
        "\n",
        "# Linear Regression Problem\n",
        "\n",
        "# f = w*x ; f = 2*x i.e. w = 2\n",
        "X = np.array([1,2,3,4], dtype=np.float32)\n",
        "y = np.array([2,4,6,8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model prediction i.e. forward pass or scoring function\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss computation = MSE\n",
        "def loss(y, y_hat):\n",
        "    return ((y_hat - y)**2).mean()\n",
        "\n",
        "# calculate gradient of loss w.r.t each parameter\n",
        "# MSE = 1/N*(w*x-y)**2\n",
        "# dJ/dw = 1/N*2*x*(w*x-y)\n",
        "def gradient(x, y, y_hat):\n",
        "    return np.dot(2*x, y_hat-y).mean()\n",
        "\n",
        "print(\"Prediction before training: f(5) = {:.3f}\".format(forward(5)))\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    y_hat = forward(X)\n",
        "    l = loss(y, y_hat)\n",
        "    dw = gradient(X, y, y_hat)\n",
        "    w = w - learning_rate*dw\n",
        "    if epoch%2 == 0:\n",
        "        print(\"epoch: {}: w = {:.3f}, loss = {:.8f}\".format(epoch, w, l))\n",
        "\n",
        "print(\"Prediction after training: f(5) = {:.3f}\".format(forward(5)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch: 0: w = 1.200, loss = 30.00000000\n",
            "epoch: 2: w = 1.872, loss = 0.76800019\n",
            "epoch: 4: w = 1.980, loss = 0.01966083\n",
            "epoch: 6: w = 1.997, loss = 0.00050331\n",
            "epoch: 8: w = 1.999, loss = 0.00001288\n",
            "epoch: 10: w = 2.000, loss = 0.00000033\n",
            "epoch: 12: w = 2.000, loss = 0.00000001\n",
            "epoch: 14: w = 2.000, loss = 0.00000000\n",
            "epoch: 16: w = 2.000, loss = 0.00000000\n",
            "epoch: 18: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZadT6BZlFV0"
      },
      "source": [
        "# Now with PyTorch (gradients)\n",
        "\n",
        "# f = w*x ; f = 2*x i.e. w = 2\n",
        "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, requires_grad=True, dtype=torch.float32)\n",
        "\n",
        "# model prediction i.e. forward pass or scoring function\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss computation = MSE\n",
        "def loss(y, y_hat):\n",
        "    return ((y_hat - y)**2).mean()\n",
        "\n",
        "print(\"Prediction before training: f(5) = {:.3f}\".format(forward(5)))\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    y_hat = forward(X)\n",
        "    l = loss(y, y_hat)\n",
        "    l.backward() # dloss/dw\n",
        "    with torch.no_grad():\n",
        "        w = w - learning_rate*w.grad # update weights\n",
        "    # zero the gradients\n",
        "    w.grad.zero_()\n",
        "    if epoch%2 == 0:\n",
        "        print(\"epoch: {}: w = {:.3f}, loss = {:.8f}\".format(epoch, w, l))\n",
        "\n",
        "print(\"Prediction after training: f(5) = {:.3f}\".format(forward(5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0Xt0yeynIs5"
      },
      "source": [
        "# PyTorch training pipeline (forward, loss, gradient, optimizer)\n",
        "\n",
        "# Training Pipeline :=>\n",
        "# 1) Design Model (input, output, forward pass)\n",
        "# 2) Construct loss and optimzer\n",
        "# 3) Training loop :\n",
        "#       -- forward pass : compute prediction/scoring function\n",
        "#       -- calculate loss\n",
        "#       -- backward pass : compute gradients\n",
        "#       -- update weights\n",
        "\n",
        "import torch.nn as nn"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqboap9Bydqx",
        "outputId": "a9401e16-dfbc-4bf2-a01e-d900c149e602"
      },
      "source": [
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
        "y = torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# model prediction i.e. forward pass or scoring function\n",
        "# def forward(x):\n",
        "#     return w * x\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "print(\"Prediction before training: f(5) = {:.3f}\".format(model(X_test).item()))\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# loss computation = MSE\n",
        "loss = nn.MSELoss()\n",
        "# optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    y_hat = model(X)\n",
        "    l = loss(y, y_hat)\n",
        "    l.backward() # dloss/dw\n",
        "    optimizer.step()\n",
        "    # zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "    if epoch%10 == 0:\n",
        "        [w, b] = model.parameters()\n",
        "        print(\"epoch: {}: w = {:.3f}, loss = {:.8f}\".format(epoch, w[0][0].item(), l))\n",
        "\n",
        "print(\"Prediction after training: f(5) = {:.3f}\".format(model(X_test).item()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 1\n",
            "Prediction before training: f(5) = 3.849\n",
            "epoch: 0: w = 0.775, loss = 9.54336452\n",
            "epoch: 10: w = 1.485, loss = 0.45141166\n",
            "epoch: 20: w = 1.609, loss = 0.20427784\n",
            "epoch: 30: w = 1.638, loss = 0.18667367\n",
            "epoch: 40: w = 1.652, loss = 0.17566046\n",
            "epoch: 50: w = 1.662, loss = 0.16543232\n",
            "epoch: 60: w = 1.672, loss = 0.15580316\n",
            "epoch: 70: w = 1.682, loss = 0.14673464\n",
            "epoch: 80: w = 1.692, loss = 0.13819385\n",
            "epoch: 90: w = 1.701, loss = 0.13015029\n",
            "Prediction after training: f(5) = 9.400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-8qYwgEydmT"
      },
      "source": [
        "# If we were to make our own custom model :=>\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, ,self).__init__()\n",
        "        # defining layers\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return self.linear(X)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "# This does the same thing as : model = nn.Linear(input_size, output_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09ui2GRoR5jB"
      },
      "source": [
        "LINEAR REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy6X4k8lSRrh"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIbU52Y2VTd9"
      },
      "source": [
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # layers\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.linear(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1E66wJM9iHZ",
        "outputId": "3f710ec3-1f7f-41e5-da3f-a9a6787f5215"
      },
      "source": [
        "# step 1: prepare data\n",
        "X_np, y_np = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "\n",
        "X = torch.from_numpy(X_np.astype(np.float32))\n",
        "y = torch.from_numpy(y_np.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# step 2: model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "# step 3: loss and optimizer\n",
        "learning_rate = 0.01\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# step 4: training\n",
        "n_epochs = 100\n",
        "for epoch in range(n_epochs):\n",
        "    # forward propagation\n",
        "    y_pred = model(X)\n",
        "    # compute loss\n",
        "    l = loss(y, y_pred)\n",
        "    # backward propagation and compute gradients\n",
        "    l.backward()\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "    # empy the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1)%10 == 0:\n",
        "        print(\"epoch: {}: loss = {:.8f}\".format(epoch, l.item()))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 9: loss = 4344.65869141\n",
            "epoch: 19: loss = 3243.06103516\n",
            "epoch: 29: loss = 2445.77050781\n",
            "epoch: 39: loss = 1868.12219238\n",
            "epoch: 49: loss = 1449.20239258\n",
            "epoch: 59: loss = 1145.12182617\n",
            "epoch: 69: loss = 924.21795654\n",
            "epoch: 79: loss = 763.61657715\n",
            "epoch: 89: loss = 646.77465820\n",
            "epoch: 99: loss = 561.71447754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "mYtV9z6W9iDb",
        "outputId": "057b25d3-fb48-43ae-efc6-acef9806c80a"
      },
      "source": [
        "# plotting the training graph\n",
        "y_preds = model(X).detach().numpy() # detaching so that pytorch doesn't include this step in it's computation graph\n",
        "plt.plot(X_np, y_np, 'ro')\n",
        "plt.plot(X_np, y_preds, 'b')\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvhZPra4XMPQ"
      },
      "source": [
        "LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mPutT_89iBD"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qshxlw-XZHD"
      },
      "source": [
        "# step 1: prepare data\n",
        "breastCancerData = datasets.load_breast_cancer()\n",
        "X, y = breastCancerData.data, breastCancerData.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "scalar = StandardScaler() # scaling : 0 mean and 1 variance\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izQAFMkoXZC9"
      },
      "source": [
        "# step 2: model\n",
        "\n",
        "# f = w*x+b, followed by sigmoid function\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        # layer\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        return torch.sigmoid(self.linear(X))\n",
        "\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "model = LogisticRegression(input_size, output_size)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeUTiHc5XZAU",
        "outputId": "0bd14ee9-07f7-44ee-df3f-52abbf7eb6ad"
      },
      "source": [
        "# step 3: loss and optimizer\n",
        "learning_rate = 0.01\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# step 4: training\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_pred = model(X_train)\n",
        "    l = loss(y_pred, y_train)\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1)%10 == 0:\n",
        "        print(\"epoch: {}: loss = {:.8f}\".format(epoch, l.item()))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 9: loss = 0.60327399\n",
            "epoch: 19: loss = 0.49055237\n",
            "epoch: 29: loss = 0.41807005\n",
            "epoch: 39: loss = 0.36836666\n",
            "epoch: 49: loss = 0.33242160\n",
            "epoch: 59: loss = 0.30527392\n",
            "epoch: 69: loss = 0.28402448\n",
            "epoch: 79: loss = 0.26689047\n",
            "epoch: 89: loss = 0.25272787\n",
            "epoch: 99: loss = 0.24077550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh6V_6NYXY9U",
        "outputId": "8eed2225-7772-4311-ed69-e0745fbbade6"
      },
      "source": [
        "with torch.no_grad(): # to avoid grads calcs in torch computation graph\n",
        "    y_preds = model(X_test)\n",
        "    y_preds_classes = y_preds.round()\n",
        "    accuracy = y_preds_classes.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(\"Accuracy = {:.4f}\".format(accuracy))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9McWqKNzNuX"
      },
      "source": [
        "PYTORCH DATASET AND DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHzMXRvJcsuu"
      },
      "source": [
        "import math\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEIiqJCKctQr"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # data loading\n",
        "        data = np.loadtxt(\"/content/sample_data/wine.csv\", delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "        self.X = torch.from_numpy(data[:, 1:])\n",
        "        self.Y = torch.from_numpy(data[:, [0]])\n",
        "        self.n_samples = data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # for indexing, dataset[0]\n",
        "        return self.X[index], self.Y[index]\n",
        "    \n",
        "    def __len__(self):\n",
        "        # len(dataset)\n",
        "        return self.n_samples"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpoBmQbZzcKh",
        "outputId": "1a6d30ed-1dce-4000-dba0-f49436ef0b0d"
      },
      "source": [
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# training\n",
        "n_epochs = 2\n",
        "batch_size = 4\n",
        "total_samples = len(dataset)\n",
        "n_iters = math.ceil(total_samples/batch_size)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        # calculations\n",
        "        if (i+1)%5 == 0:\n",
        "            print(\"epoch {}/{}, step {}/{}, inputs {}\".format(epoch+1, n_epochs, i+1, n_iters, inputs.shape))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
            "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGDV3xUyr_If"
      },
      "source": [
        "SOFTMAX ACTIVATION FUNCTION AND CROSSENTROPY LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPRZT_dAzcGL",
        "outputId": "ae26c363-bf26-4b36-d459-c868a34e813c"
      },
      "source": [
        "# Activation functions : actvation functions apply a non-linear transformation and decide whether a neuron should be activated or not.\n",
        "# softmax activation function :- squashes the output to be between 0 and 1 so we get probabilities.\n",
        "\n",
        "# implementing softmax activation function in numpy\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print(outputs)\n",
        "\n",
        "# implementing softmax activation function in pytorch\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0)\n",
        "print(outputs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.65900114 0.24243297 0.09856589]\n",
            "tensor([0.6590, 0.2424, 0.0986])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VelhAbNxzcDZ",
        "outputId": "31bce0c3-eced-4321-8b42-5da87f5f953e"
      },
      "source": [
        "# Crossentropy Loss :- this measures the performance of our CLASSIFICATION MODEL whose output is a probability btw 0 and 1.\n",
        "# It can be used in multiclass problems.\n",
        "# CEL(y_pred, y) = -(1/N)*np.sum(y*np.log(y_pred))\n",
        "\n",
        "# In Numpy\n",
        "\n",
        "def cross_entropy_loss(y, y_pred):\n",
        "    return -np.sum(y*np.log(y_pred))\n",
        "\n",
        "# y must be one-hot encoded; i.e. \n",
        "# if class 0, y = [1,0,0]\n",
        "# if class 1, y = [0,1,0]\n",
        "# if class 2, y = [0,0,1]\n",
        "y = np.array([1,0,0])\n",
        "\n",
        "# y_pred has probabilities\n",
        "y_pred_good = np.array([0.7,0.2,0.1])\n",
        "y_pred_bad = np.array([0.1,0.3,0.6])\n",
        "\n",
        "l1 = cross_entropy_loss(y, y_pred_good)\n",
        "l2 = cross_entropy_loss(y, y_pred_bad)\n",
        "\n",
        "print(\"loss 1: {:.4f}\".format(l1))\n",
        "print(\"loss 2: {:.4f}\".format(l2))\n",
        "\n",
        "# In PyTorch\n",
        "\n",
        "loss = nn.CrossEntropyLoss() \n",
        "# this loss already applies nn.LogSoftmax + nn.NLLLoss (neg log likelihood loss)\n",
        "# so we must not implement softmax layer ourselves.\n",
        "# Also for this nn.CrossEntropyLoss(), Y has class labels, not one-hot and y_pred has raw scores(logits) no softmax.\n",
        "\n",
        "y = torch.tensor([0])\n",
        "# nsamples*nclasses = 1x3\n",
        "\n",
        "y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "\n",
        "print(\"loss 1: {:.4f}\".format(l1))\n",
        "print(\"loss 2: {:.4f}\".format(l2))\n",
        "\n",
        "_, pred1 = torch.max(y_pred_good, 1)\n",
        "_, pred2 = torch.max(y_pred_bad, 1)\n",
        "\n",
        "print(pred1)\n",
        "print(pred2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 1: 0.3567\n",
            "loss 2: 2.3026\n",
            "loss 1: 0.4170\n",
            "loss 2: 1.8406\n",
            "tensor([0])\n",
            "tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0UtHSS17VE7"
      },
      "source": [
        "NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ-WcTJw9Lv0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision # for datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjXTk1Tz9Lrg"
      },
      "source": [
        "# device config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# hyperparameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST data\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./\",\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./\",\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# Dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples, labels = examples.next()\n",
        "print(samples.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "3UWl6h8x_Qxr",
        "outputId": "93b0ad3a-2d40-4946-f52a-639a84357532"
      },
      "source": [
        "# plotting samples\n",
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDiVCL8lwaMj",
        "outputId": "96cef20c-5872-43c4-8cf8-db1ee5cac7db"
      },
      "source": [
        "# model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        # layers\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, X):\n",
        "        out = self.linear1(X)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # out = self.sigmoid(out) # as this is a multiclass problem, don't apply softmax fun\n",
        "        return out\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "\n",
        "# loss and optimizer\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# training\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward prop\n",
        "        y_pred = model(images)\n",
        "        # compute loss\n",
        "        l = loss(y_pred, labels)\n",
        "        # backward prop\n",
        "        l.backward()\n",
        "        # weights update\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if (i+1)%100 == 0:\n",
        "            print(\"epoch {}/{}, step {}/{}, loss = {:.8f}\".format(epoch+1, num_epochs, i+1, n_total_steps, l.item()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/2, step 100/600, loss = 0.54439235\n",
            "epoch 1/2, step 200/600, loss = 0.30515817\n",
            "epoch 1/2, step 300/600, loss = 0.29702604\n",
            "epoch 1/2, step 400/600, loss = 0.16601175\n",
            "epoch 1/2, step 500/600, loss = 0.11688229\n",
            "epoch 1/2, step 600/600, loss = 0.19543718\n",
            "epoch 2/2, step 100/600, loss = 0.28708392\n",
            "epoch 2/2, step 200/600, loss = 0.08348958\n",
            "epoch 2/2, step 300/600, loss = 0.20402947\n",
            "epoch 2/2, step 400/600, loss = 0.23433864\n",
            "epoch 2/2, step 500/600, loss = 0.24089774\n",
            "epoch 2/2, step 600/600, loss = 0.31893793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hdAEApXwbUb",
        "outputId": "e046ef1b-fd35-4e72-f68c-546117e39d9c"
      },
      "source": [
        "# testing\n",
        "with torch.no_grad():\n",
        "\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1) # value, index\n",
        "        n_samples += labels.shape[0]\n",
        "        n_correct += (preds == labels).sum().item()\n",
        "    \n",
        "    accuracy = 100*(n_correct/n_samples)\n",
        "    print(\"Accuracy: {:.2f}\".format(accuracy))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 95.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l8KHG5Q4K-x"
      },
      "source": [
        "CONVOLUTIONAL NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAOt8vrNwbQK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1]. \n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llSeM4et4Y22"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5cIeG3y4YzO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHT8EWY54YxF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}